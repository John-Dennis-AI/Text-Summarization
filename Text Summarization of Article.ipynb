{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Customizable Summary from a Text File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the body of text (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speech from Adm. McRaven UT-Austin Graduation 2014\n",
    "path = 'C:\\\\Users\\\\John\\\\Adm_McRaven_UT_Aus_2014.txt'\n",
    "f = open(path,encoding=\"utf8\")\n",
    "text_body = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize corpus into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = nltk.sent_tokenize(text_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find word frequencies in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in nltk.word_tokenize(text_body):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weighted frequencies of words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sentence scores for sentences with frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_scores = {}\n",
    "for sentence in sent_list:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            if sentence not in sent_scores.keys():\n",
    "                sent_scores[sentence] = word_freq[word]\n",
    "            else:\n",
    "                sent_scores[sentence] += word_freq[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank the sentences according to frequency score, and produce a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_summary = heapq.nlargest(len(sent_scores), sent_scores, key=sent_scores.get)\n",
    "final_summary = '  '.join(sentence_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask if user wants minimum words or percent length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want (m)inimum words or (p)ercent length?p\n",
      "Enter percent length:10\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Do you want (m)inimum words or (p)ercent length?\")\n",
    "\n",
    "if query == 'm':\n",
    "    qtype = 'm'\n",
    "    min_words = int(input(\"Enter minimum words:\"))\n",
    "    if min_words < 0:\n",
    "        min_words = 1\n",
    "    if min_words > len(final_summary.split()):\n",
    "        min_words = len(final_summary.split())\n",
    "else:\n",
    "    qtype = 'p'\n",
    "    pct_len = int(input(\"Enter percent length:\"))\n",
    "    if pct_len < 0:\n",
    "        pctlen = 0\n",
    "    if pct_len > 100:\n",
    "        pct_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words in the summary string are : 3156\n",
      "The requested percentage of words from the summary string are : 10%, or 315 words\n",
      "\n",
      "But the keel is also the darkest part of the ship — where you cannot see your hand in front of your face, where the noise from the ship’s machinery is deafening and where it is easy to get disoriented and fail.Every SEAL knows that under the keel, at the darkest moment of the mission, is the time when you must be calm, composed — when all your tactical skills, your physical power and all your inner strength must be brought to bear.If you want to change the world, you must be your very best in the darkest moment.The ninth week of training is referred to as “Hell Week.” It is six days of no sleep, constant physical and mental harassment, and one special day at the Mud Flats. The power of one person — Washington, Lincoln, King, Mandela and even a young girl from Pakistan, Malala — one person can change the world by giving people hope.So, if you want to change the world, start singing when you’re up to your neck in mud.Finally, in SEAL training there is a bell. I was in the boat with the tall guys, but the best boat crew we had was made up of the the little guys — the munchkin crew we called them — no one was over about five-foot-five.The munchkin boat crew had one American Indian, one African American, one Polish American, one Greek American, one Italian American, and two tough kids from the midwest. You can’t change the world alone — you will need some help — and to truly get from your starting point to your destination takes friends, colleagues, the good will of strangers and a strong coxswain to guide them.If you want to change the world, find someone to help you paddle.Over a few weeks of difficult training my SEAL class, which started with 150 men, was down to just\n"
     ]
    }
   ],
   "source": [
    "sum_words = len(final_summary.split())\n",
    "print (\"The total number of words in the summary string are : \" +  str(sum_words))\n",
    "\n",
    "if qtype == 'm':\n",
    "    num_words = min_words\n",
    "    print (\"The requested minimum number of words displayed in the summary string are : \" +  str(num_words) + \" words, or \" + str(int(num_words/sum_words*100)) + \"%\")\n",
    "    print(\"\")\n",
    "else:\n",
    "    num_words = int(pct_len/100 * sum_words)\n",
    "    print (\"The requested percentage of words from the summary string are : \" +  str(pct_len) + \"%, or \" + str(num_words) + \" words\")\n",
    "    print(\"\")\n",
    "print(' '.join(final_summary.split()[:num_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
