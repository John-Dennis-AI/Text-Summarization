{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a short summary from text content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the body of text (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_body = \"\"\"\n",
    "Just A Rather Very Intelligent System a.k.a JARVIS is created by Tony Stark natural-language and a\n",
    "sophisticated artificial intelligence user interface computer system, named after Edwin Jarvis, the butler\n",
    "who worked for Howard Stark. Though its primary duty is to automate Stark’s Malibu estate, the lifelike\n",
    "program fulfills many other needs for Stark, like being an information source for him, a diagnostic tool, a\n",
    "consultant and a voice of reason in Stark’s life. It was also responsible to provide security for Tony\n",
    "Stark's Mansion and Stark Tower. After creating the Mark II armor, Stark uploaded JARVIS into all of\n",
    "the Iron Man Armors, as well as allowing him to interact with the other Avengers, giving them valuable\n",
    "information during combat. JARVIS may be the one intellect Stark feels most comfortable opening up to.\n",
    "JARVIS can object to Stark’s commands if necessary. JARVIS speaks with a refined British accent, and\n",
    "is capable of back talk, sarcasm and condescension. During the Ultron Offensive, JARVIS was destroyed\n",
    "by Ultron, although his remaining programming codes unknowingly continued to thwart Ultron's plans of\n",
    "gaining access to nuclear missiles. His remains were found by Stark, who uploaded them into a synthetic\n",
    "body made of vibranium and, in conjunction with Ultron's personality and an Infinity Stone. JARVIS'\n",
    "duties were then taken over by FRIDAY.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize corpus into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = nltk.sent_tokenize(text_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find word frequencies in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in nltk.word_tokenize(text_body):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weighted frequencies of words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sentence scores for sentences with frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_scores = {}\n",
    "for sentence in sent_list:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            if sentence not in sent_scores.keys():\n",
    "                sent_scores[sentence] = word_freq[word]\n",
    "            else:\n",
    "                sent_scores[sentence] += word_freq[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank the sentences according to frequency score, and produce a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_summary = heapq.nlargest(len(sent_scores), sent_scores, key=sent_scores.get)\n",
    "final_summary = '  '.join(sentence_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask if user wants minimum words or percent length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want (m)inimum words or (p)ercent length?p\n",
      "Enter percent length:25\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Do you want (m)inimum words or (p)ercent length?\")\n",
    "\n",
    "if query == 'm':\n",
    "    qtype = 'm'\n",
    "    min_words = int(input(\"Enter minimum words:\"))\n",
    "    if min_words < 0:\n",
    "        min_words = 1\n",
    "    if min_words > len(final_summary.split()):\n",
    "        min_words = len(final_summary.split())\n",
    "else:\n",
    "    qtype = 'p'\n",
    "    pct_len = int(input(\"Enter percent length:\"))\n",
    "    if pct_len < 0:\n",
    "        pctlen = 0\n",
    "    if pct_len > 100:\n",
    "        pct_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words in the summary string are : 217\n",
      "The requested percentage of words from the summary string are : 25%, or 54 words\n",
      "Though its primary duty is to automate Stark’s Malibu estate, the lifelike program fulfills many other needs for Stark, like being an information source for him, a diagnostic tool, a consultant and a voice of reason in Stark’s life. After creating the Mark II armor, Stark uploaded JARVIS into all of the Iron Man\n"
     ]
    }
   ],
   "source": [
    "sum_words = len(final_summary.split())\n",
    "print (\"The total number of words in the summary string are : \" +  str(sum_words))\n",
    "\n",
    "if qtype == 'm':\n",
    "    num_words = min_words\n",
    "    print (\"The requested minimum number of words displayed in the summary string are : \" +  str(num_words) + \" words, or \" + str(int(num_words/sum_words*100)) + \"%\")\n",
    "else:\n",
    "    num_words = int(pct_len/100 * sum_words)\n",
    "    print (\"The requested percentage of words from the summary string are : \" +  str(pct_len) + \"%, or \" + str(num_words) + \" words\")\n",
    "print(' '.join(final_summary.split()[:num_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
